{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-25T16:44:44.734146Z",
     "iopub.status.busy": "2023-06-25T16:44:44.734009Z",
     "iopub.status.idle": "2023-06-25T16:44:45.237050Z",
     "shell.execute_reply": "2023-06-25T16:44:45.236414Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data_dir = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/'\n",
    "train_record_ids = os.listdir(f\"{comp_data_dir}/train/\")\n",
    "valid_record_ids = os.listdir(f\"{comp_data_dir}/validation/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labelers_list = []\n",
    "for train_record_id in tqdm(train_record_ids):\n",
    "    human_individual_masks = np.load(f\"{comp_data_dir}/train/{train_record_id}/human_individual_masks.npy\")\n",
    "    num_labelers = human_individual_masks.shape[3]\n",
    "    num_labelers_list.append(num_labelers)\n",
    "\n",
    "labelers_unique_count = collections.Counter(num_labelers_list)\n",
    "sorted(labelers_unique_count.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_range(data, bounds):\n",
    "    \"\"\"Maps data to the range [0, 1].\"\"\"\n",
    "    return (data - bounds[0]) / (bounds[1] - bounds[0])\n",
    "\n",
    "\n",
    "def get_false_color(record_data):\n",
    "    _T11_BOUNDS = (243, 303)\n",
    "    _CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n",
    "    _TDIFF_BOUNDS = (-4, 2)\n",
    "\n",
    "    r = normalize_range(record_data[\"band_15\"] - record_data[\"band_14\"], _TDIFF_BOUNDS)\n",
    "    g = normalize_range(record_data[\"band_14\"] - record_data[\"band_11\"], _CLOUD_TOP_TDIFF_BOUNDS)\n",
    "    b = normalize_range(record_data[\"band_14\"], _T11_BOUNDS)\n",
    "    images = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_record(record_id, comp_data_dir, mode):\n",
    "    record_data = {}\n",
    "    if mode in [\"train\"]:\n",
    "        bands_mask = [\"band_11\", \"band_14\", \"band_15\", \"human_individual_masks\"]\n",
    "    if mode in [\"validation\"]:\n",
    "        bands_mask = [\"band_11\", \"band_14\", \"band_15\", \"human_pixel_masks\"]\n",
    "    if mode in [\"test\"]:\n",
    "        bands_mask = [\"band_11\", \"band_14\", \"band_15\"]\n",
    "\n",
    "    for x in bands_mask:\n",
    "        record_data[x] = np.load(os.path.join(comp_data_dir, record_id, x + \".npy\"))\n",
    "    return record_data\n",
    "\n",
    "\n",
    "def process_individual_masks(human_individual_masks):\n",
    "    num_masks = human_individual_masks.shape[-1]\n",
    "    masks_sum = np.zeros(human_individual_masks[..., 0].shape)\n",
    "    for i in range(num_masks):\n",
    "        masks_sum += human_individual_masks[..., i]\n",
    "    mask_agree = masks_sum/num_masks\n",
    "    mask = []\n",
    "    for p_agree in [0, 1/4, 2/4, 3/4]:\n",
    "        mask.append(np.where(mask_agree > p_agree, 1, 0))\n",
    "    mask = np.dstack(mask)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_dataset(comp_data_dir, dataset_dir, image_dir, label_dir, mode):\n",
    "    N_TIMES = 8\n",
    "    N_TIMES_LABELED = 4\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "    input_dir = f\"{comp_data_dir}/{mode}\"\n",
    "    record_ids = os.listdir(input_dir)\n",
    "\n",
    "    df = pd.DataFrame(record_ids, columns=['record_id'])\n",
    "    df['image_path'] = image_dir + df['record_id'].astype(str) + '.npy'\n",
    "    df['label_path'] = label_dir + df['record_id'].astype(str) + f'_{N_TIMES_LABELED}.npy'\n",
    "    df = pd.DataFrame({\n",
    "        'record_id': df['record_id'].repeat(N_TIMES),\n",
    "        'image_path': [f\"{image_path.split('.')[0]}_{time}.npy\" for image_path in df['image_path'] for time in range(N_TIMES)],\n",
    "        'time': [time for image_path in df['image_path'] for time in range(N_TIMES)],\n",
    "        'label_path': [label_path if time==N_TIMES_LABELED else \"\" for label_path in df['label_path'] for time in range(N_TIMES)]\n",
    "    })\n",
    "    df.to_csv(f\"{dataset_dir}/{mode}_df.csv\", index=False)\n",
    "\n",
    "    for record_id in tqdm(record_ids):\n",
    "        record_data = read_record(str(record_id), input_dir, mode)\n",
    "        \n",
    "        images = get_false_color(record_data)\n",
    "        for time in range(N_TIMES):\n",
    "            image = images[..., time]\n",
    "            image = np.dstack([image])\n",
    "            image = image.astype(np.float16)\n",
    "            npy_image_path = f\"{image_dir}/{record_id}_{time}.npy\"\n",
    "            np.save(str(npy_image_path), image)\n",
    "        \n",
    "        if mode in [\"train\",]:\n",
    "            label = process_individual_masks(record_data['human_individual_masks'])\n",
    "        if mode in [\"validation\",]:\n",
    "            label = record_data['human_pixel_masks']\n",
    "        if mode in [\"test\"]:\n",
    "            continue\n",
    "        label = label.astype(np.float16)\n",
    "        npy_label_path = f\"{label_dir}/{record_id}_{N_TIMES_LABELED}.npy\"\n",
    "        np.save(str(npy_label_path), label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train =\"/kaggle/working/dataset_train/pseud_ashcolor_4label/\"\n",
    "dataset_train_images = f\"{dataset_train}images/\"\n",
    "dataset_train_labels = f\"{dataset_train}labels/true/\"\n",
    "dataset_test = \"/kaggle/working/dataset_test/pseud_ashcolor_4label/images/\"\n",
    "\n",
    "create_dataset(comp_data_dir, dataset_train, dataset_train_images, dataset_train_labels, \"train\")\n",
    "create_dataset(comp_data_dir, dataset_train, dataset_train_images, dataset_train_labels, \"validation\")\n",
    "# # create_dataset(comp_data_dir, dataset_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

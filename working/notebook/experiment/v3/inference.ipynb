{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "is_kaggle_notebook = \"kaggle_web_client\" in sys.modules\n",
    "if is_kaggle_notebook:\n",
    "    %pip uninstall timm -y\n",
    "    \n",
    "sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\n",
    "sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\n",
    "sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models.pytorch-master')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # ============== comp exp name =============\n",
    "    comp_name = 'contrail'\n",
    "    comp_dir_path = '/kaggle/input/'\n",
    "    comp_folder_name = 'google-research-identify-contrails-reduce-global-warming'\n",
    "\n",
    "    dataset_path = \"/kaggle/working/dataset_test/ash_color/\"\n",
    "\n",
    "    pth_paths=[\n",
    "                \"/kaggle/working/notebook/experiment/v3/model1_iter1/model1_iter1/model1_iter1_fold0.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model1_iter1/model1_iter1/model1_iter1_fold1.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model1_iter2/model1_iter2/model1_iter2_fold0.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model1_iter2/model1_iter2/model1_iter2_fold1.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model1_iter2/model1_iter2/model1_iter2_fold2.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model1_iter3/model1_iter3/model1_iter3_fold0.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model1_iter3/model1_iter3/model1_iter3_fold1.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model1_iter3/model1_iter3/model1_iter3_fold2.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model2_iter1/model2_iter1/model2_iter1_fold0.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model2_iter1/model2_iter1/model2_iter1_fold1.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model2_iter1/model2_iter1/model2_iter1_fold2.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model3_iter1/model3_iter1/model3_iter1_fold0.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model3_iter1/model3_iter1/model3_iter1_fold1.pth\",\n",
    "                \"/kaggle/working/notebook/experiment/v3/model3_iter1/model3_iter1/model3_iter1_fold2.pth\",\n",
    "               ]\n",
    "    if is_kaggle_notebook:\n",
    "        pth_paths=glob(\"/kaggle/input/modelsv1/**/*.pth\",recursive=True)\n",
    "    \n",
    "    # ============== model =============\n",
    "    TTA = is_kaggle_notebook\n",
    "    thresh = 0.00000005\n",
    "    # ============== training cfg =============\n",
    "    valid_batch_size = 32\n",
    "\n",
    "    # ============== fixed =============\n",
    "    num_workers = 4\n",
    "    seed = 42\n",
    "\n",
    "    # ============== augmentation =============\n",
    "\n",
    "    valid_aug_list = [\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_record(record_id, directory, mode):\n",
    "    record_data = {}\n",
    "    if mode in [\"train\", \"validation\"]:\n",
    "        bands_mask = [\"band_11\", \"band_14\", \"band_15\", \"human_pixel_masks\"]\n",
    "    if mode == \"test\":\n",
    "        bands_mask = [\"band_11\", \"band_14\", \"band_15\"]\n",
    "\n",
    "    for x in bands_mask:\n",
    "        record_data[x] = np.load(os.path.join(directory, record_id, x + \".npy\"))\n",
    "    return record_data\n",
    "\n",
    "\n",
    "def normalize_range(data, bounds):\n",
    "    return (data - bounds[0]) / (bounds[1] - bounds[0])\n",
    "\n",
    "\n",
    "def get_false_color(record_data):\n",
    "    _T11_BOUNDS = (243, 303)\n",
    "    _CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n",
    "    _TDIFF_BOUNDS = (-4, 2)\n",
    "\n",
    "    N_TIMES_BEFORE = 4\n",
    "\n",
    "    r = normalize_range(record_data[\"band_15\"] - record_data[\"band_14\"], _TDIFF_BOUNDS)\n",
    "    g = normalize_range(record_data[\"band_14\"] - record_data[\"band_11\"], _CLOUD_TOP_TDIFF_BOUNDS)\n",
    "    b = normalize_range(record_data[\"band_14\"], _T11_BOUNDS)\n",
    "    false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n",
    "    img = false_color[..., N_TIMES_BEFORE]\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 27.16it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(data_dir, save_dir, mode):\n",
    "    input_dir=f\"{data_dir}/{mode}\"\n",
    "    ids = os.listdir(input_dir)\n",
    "    df = pd.DataFrame(ids, columns=['record_id'])\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    df['path'] = save_dir + df['record_id'].astype(str) + '.npy'\n",
    "    df.to_csv(f\"{save_dir}/{mode}_df.csv\", index=False)\n",
    "\n",
    "    for record_id in tqdm(ids):\n",
    "        data = read_record(str(record_id), input_dir, mode)\n",
    "        images = get_false_color(data)\n",
    "        if mode in [\"train\", \"validation\"]:\n",
    "            array = np.dstack([images, data['human_pixel_masks']])\n",
    "        if mode == \"test\":\n",
    "            array = np.dstack([images])\n",
    "        array = array.astype(np.float16)\n",
    "\n",
    "        npy_path = f\"{save_dir}/{record_id}.npy\"\n",
    "        np.save(str(npy_path), array)\n",
    "\n",
    "\n",
    "data_dir = f'{CFG.comp_dir_path}/{CFG.comp_folder_name}'\n",
    "create_dataset(data_dir, CFG.dataset_path, \"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fastnumpyio:\n",
    "    def load(file):\n",
    "        file = open(file, \"rb\")\n",
    "        header = file.read(128)\n",
    "        descr = str(header[19:25], 'utf-8').replace(\"'\", \"\").replace(\" \", \"\")\n",
    "        shape = tuple(int(num) for num in str(header[60:120], 'utf-8').replace(', }', '').replace('(', '').replace(')', '').split(','))\n",
    "        datasize = np.lib.format.descr_to_dtype(descr).itemsize\n",
    "        for dimension in shape:\n",
    "            datasize *= dimension\n",
    "        return np.ndarray(shape, dtype=descr, buffer=file.read(datasize))\n",
    "\n",
    "\n",
    "class ContrailsDataset(Dataset):\n",
    "    def __init__(self, df, transform, mode='train'):\n",
    "        self.df = df\n",
    "        self.transform = A.Compose(transform)\n",
    "        self.mode = mode\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if self.mode == 'valid':\n",
    "            row = self.df.iloc[index]\n",
    "            record_id = row[\"record_id\"]\n",
    "            image_path = row[\"image_path\"]\n",
    "            label_path = row[\"label_path\"]\n",
    "            image = fastnumpyio.load(str(image_path)).astype(\"float32\")\n",
    "            label = fastnumpyio.load(str(label_path)).astype(\"float32\")\n",
    "            data = self.transform(image=image, mask=label)\n",
    "            image = data['image']\n",
    "            label = data['mask']\n",
    "            image = torch.tensor(image)\n",
    "            return image.float(), label.float()\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            row = self.df.iloc[index]\n",
    "            path = row.path\n",
    "            record_id = row.record_id\n",
    "            npy = fastnumpyio.load(str(path))\n",
    "            image = npy\n",
    "            data = self.transform(image=image)\n",
    "            image = data['image']\n",
    "            image = torch.tensor(image)\n",
    "            return image.float(), record_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000834164244036115</td>\n",
       "      <td>/kaggle/working/dataset_test/ash_color/1000834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002653297254493116</td>\n",
       "      <td>/kaggle/working/dataset_test/ash_color/1002653...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             record_id                                               path\n",
       "0  1000834164244036115  /kaggle/working/dataset_test/ash_color/1000834...\n",
       "1  1002653297254493116  /kaggle/working/dataset_test/ash_color/1002653..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(f\"{CFG.dataset_path}/test_df.csv\")\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len(dataset_test) = 2\n",
      "test_image_shape : torch.Size([3, 256, 256])\n",
      "test_image_dtype : torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_test = ContrailsDataset(test_df, CFG.valid_aug_list, mode='test')\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=CFG.valid_batch_size, num_workers=CFG.num_workers)\n",
    "\n",
    "print(f\"\"\"\n",
    "{len(dataset_test) = }\n",
    "test_image_shape : {dataset_test[0][0].shape}\n",
    "test_image_dtype : {dataset_test[0][0].dtype}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_arch, backbone, in_chans, target_size, weight):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = smp.create_model(\n",
    "            model_arch,\n",
    "            encoder_name=backbone,\n",
    "            encoder_weights=weight,\n",
    "            in_channels=in_chans,\n",
    "            classes=4,\n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        output = self.model(image)\n",
    "        return output\n",
    "\n",
    "\n",
    "def build_model(model_arch, backbone, in_chans, target_size, weight=\"imagenet\", dataparallel=True):\n",
    "    model = CustomModel(model_arch, backbone, in_chans, target_size, weight)\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    device_ids = list(range(num_gpus))\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if dataparallel:\n",
    "        model = nn.DataParallel(model, device_ids=device_ids)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dice(nn.Module):\n",
    "    def __init__(self, use_sigmoid=True):\n",
    "        super(Dice, self).__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        if self.use_sigmoid:\n",
    "            inputs = self.sigmoid(inputs)\n",
    "\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.0 * intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return dice\n",
    "\n",
    "\n",
    "def calc_dice_score(pred, true, thresh: float) -> float:\n",
    "    dice = Dice(use_sigmoid=False)\n",
    "    pred_thresh = np.where(pred > thresh, 1, 0)\n",
    "    pred_thresh = torch.flatten(torch.from_numpy(pred_thresh))\n",
    "    return dice(true, pred_thresh).item()\n",
    "\n",
    "\n",
    "def calc_optim_thresh(pred, true, threshs_to_test):\n",
    "    best_dice = -1\n",
    "    for thresh in threshs_to_test:\n",
    "        dice = calc_dice_score(pred, true, thresh)\n",
    "        if dice > best_dice:\n",
    "            best_dice = dice\n",
    "            best_thresh = thresh\n",
    "    return best_dice, best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    len(dataset_valid) = 1856\n",
      "    valid_image_shape : torch.Size([3, 256, 256])\n",
      "    valid_mask_shape  : torch.Size([1, 256, 256])\n",
      "    valid_image_dtype : torch.float32\n",
      "    valid_mask_dtype : torch.float32\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "if not is_kaggle_notebook:\n",
    "    valid_df = pd.read_csv(f\"/kaggle/working/dataset_train/pseud_ashcolor_4label/validation_df.csv\")\n",
    "    valid_df = valid_df.dropna()\n",
    "    dataset_valid = ContrailsDataset(valid_df, CFG.valid_aug_list, \"valid\")\n",
    "    dataloader_valid = DataLoader(dataset_valid, batch_size=CFG.valid_batch_size, num_workers = CFG.num_workers)\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    {len(dataset_valid) = }\n",
    "    valid_image_shape : {dataset_valid[0][0].shape}\n",
    "    valid_mask_shape  : {dataset_valid[0][1].shape}\n",
    "    valid_image_dtype : {dataset_valid[0][0].dtype}\n",
    "    valid_mask_dtype : {dataset_valid[0][1].dtype}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:06<00:00,  8.48it/s]\n",
      "100%|██████████| 58/58 [00:06<00:00,  8.47it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  8.16it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  8.12it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  8.02it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  8.16it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  8.15it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  8.21it/s]\n",
      "100%|██████████| 58/58 [00:10<00:00,  5.31it/s]\n",
      "100%|██████████| 58/58 [00:11<00:00,  5.27it/s]\n",
      "100%|██████████| 58/58 [00:10<00:00,  5.30it/s]\n",
      "100%|██████████| 58/58 [00:09<00:00,  6.14it/s]\n",
      "100%|██████████| 58/58 [00:09<00:00,  6.18it/s]\n",
      "100%|██████████| 58/58 [00:09<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score : 0.6880\tthresh : 0.43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not is_kaggle_notebook:\n",
    "    cum_cum_pred = []\n",
    "\n",
    "    thresholds_to_test = [round(x * 0.01, 2) for x in range(1, 101, 2)]\n",
    "\n",
    "    for i_pth, pth_path in enumerate(CFG.pth_paths):\n",
    "        cum_true = []\n",
    "        cum_pred = []\n",
    "        pth = torch.load(pth_path)\n",
    "        try:\n",
    "            model = build_model(pth[\"model_arch\"], pth[\"backbone\"], pth[\"in_chans\"], pth[\"target_size\"], weight=None)\n",
    "            model.load_state_dict(pth['model'])\n",
    "        except RuntimeError:\n",
    "            model = build_model(pth[\"model_arch\"], pth[\"backbone\"], pth[\"in_chans\"], pth[\"target_size\"], weight=None, dataparallel=False)\n",
    "            model.load_state_dict(pth['model'])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        for i, (images, masks) in enumerate(tqdm(dataloader_valid)):\n",
    "            images, masks = images.cuda(), masks.cuda()\n",
    "            with torch.no_grad():\n",
    "                preds = model(images)[:, 2]\n",
    "                preds = torch.sigmoid(preds)\n",
    "                cum_pred.append(preds.cpu().detach().numpy())\n",
    "                cum_true.append(masks.cpu().detach().numpy())\n",
    "\n",
    "        cum_pred = (np.concatenate(cum_pred, axis=0)).flatten()\n",
    "        cum_cum_pred.append(cum_pred)\n",
    "    cum_cum_pred = np.sum(cum_cum_pred, axis=0)/len(CFG.pth_paths)\n",
    "    cum_true = torch.flatten(torch.from_numpy(np.concatenate(cum_true, axis=0)))\n",
    "    dice_score_, thresh = calc_optim_thresh(cum_cum_pred, cum_true, thresholds_to_test)\n",
    "    print(f\"score : {dice_score_:.4f}\\tthresh : {thresh}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(x):\n",
    "    if x:\n",
    "        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
    "    else:\n",
    "        s = '-'\n",
    "    return s\n",
    "\n",
    "\n",
    "def rle_encode(x, fg_val=1):\n",
    "    dots = np.where(\n",
    "        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if b > prev + 1:\n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(f'{CFG.comp_dir_path}/{CFG.comp_folder_name}/sample_submission.csv', index_col='record_id')\n",
    "\n",
    "preds_multimodels = np.zeros((len(CFG.pth_paths), len(dataset_test), 1, 256, 256))\n",
    "for i_pth, pth_path in enumerate(CFG.pth_paths):\n",
    "    pth = torch.load(pth_path)\n",
    "    try:\n",
    "        model = build_model(pth[\"model_arch\"], pth[\"backbone\"], pth[\"in_chans\"], pth[\"target_size\"], weight=None)\n",
    "        model.load_state_dict(pth['model'])\n",
    "    except RuntimeError:\n",
    "        model = build_model(pth[\"model_arch\"], pth[\"backbone\"], pth[\"in_chans\"], pth[\"target_size\"], weight=None, dataparallel=False)\n",
    "        model.load_state_dict(pth['model'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for i, (images, record_ids) in enumerate(tqdm(dataloader_test)):\n",
    "        images = images.cuda()\n",
    "        n_batch = images.shape[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(images)[:, 2]\n",
    "            preds = torch.unsqueeze(preds, 1)\n",
    "        preds = torch.sigmoid(preds).cpu().detach().numpy()\n",
    "\n",
    "        for num in range(n_batch):\n",
    "            pred = preds[num, 0, :, :]\n",
    "            record_id = int(record_ids[num])\n",
    "            submission.loc[int(record_id), f'pred_{str(i_pth)}']= \"tmp\"\n",
    "            submission.loc[int(record_id), f'pred_{str(i_pth)}'] = [pred]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(submission.itertuples()):\n",
    "    pred = np.zeros((256, 256))\n",
    "    for i_pth in range(len(CFG.pth_paths)):\n",
    "        column_name = f'pred_{str(i_pth)}'\n",
    "        i_pred = row[i_pth+2][0]\n",
    "        pred += i_pred\n",
    "    pred = pred/len(CFG.pth_paths)\n",
    "    pred_thresh = np.where(pred > CFG.thresh, 1, 0)\n",
    "\n",
    "    submission.iloc[i, 0] = list_to_string(rle_encode(pred_thresh))\n",
    "cols_to_drop = submission.columns[1:]\n",
    "submission = submission.drop(columns=cols_to_drop)\n",
    "if is_kaggle_notebook:\n",
    "    shutil.rmtree(CFG.dataset_path)\n",
    "    submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

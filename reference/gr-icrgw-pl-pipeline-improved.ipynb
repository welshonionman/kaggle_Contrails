{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Summary\n- Baseline written using Pytorch Lightning\n- resnest26d as encoder\n- Dataset is taken from: https://www.kaggle.com/datasets/shashwatraman/contrails-images-ash-color\n\n#### Improvements over [previous version](https://www.kaggle.com/code/egortrushin/gr-icrgw-pytorch-lightning-baseline-unet-resnest) (please upvote).\n- Option to change image size\n- Mixed precision training (only useful with T4x2, on P100 this slows down training). This helps to use GPU memory more efficiently\n- Training using 2 GPUs - with 2 GPUs we have more memory and higher speed\n- Other numerous small changes","metadata":{}},{"cell_type":"markdown","source":"### Training part","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/pretrained-models-pytorch\")\nsys.path.append(\"../input/efficientnet-pytorch\")\nsys.path.append(\"/kaggle/input/smp-github/segmentation_models.pytorch-master\")\nsys.path.append(\"/kaggle/input/timm-pretrained-resnest/resnest/\")\nimport segmentation_models_pytorch as smp","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-16T20:36:13.879006Z","iopub.execute_input":"2023-06-16T20:36:13.879272Z","iopub.status.idle":"2023-06-16T20:36:22.272613Z","shell.execute_reply.started":"2023-06-16T20:36:13.879247Z","shell.execute_reply":"2023-06-16T20:36:22.271527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /root/.cache/torch/hub/checkpoints/\n!cp /kaggle/input/timm-pretrained-resnest/resnest/gluon_resnest26-50eb607c.pth /root/.cache/torch/hub/checkpoints/gluon_resnest26-50eb607c.pth","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-16T20:36:22.27517Z","iopub.execute_input":"2023-06-16T20:36:22.276093Z","iopub.status.idle":"2023-06-16T20:36:25.892838Z","shell.execute_reply.started":"2023-06-16T20:36:22.276057Z","shell.execute_reply":"2023-06-16T20:36:25.8914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile config.yaml\n\ndata_path: \"/kaggle/input/contrails-images-ash-color\"\noutput_dir: \"models\"\n\nseed: 42\n\ntrain_bs: 48\nvalid_bs: 128\nworkers: 2\n\nprogress_bar_refresh_rate: 1\n\nearly_stop:\n    monitor: \"val_loss\"\n    mode: \"min\"\n    patience: 999\n    verbose: 1\n\ntrainer:\n    max_epochs: 26\n    min_epochs: 26\n    enable_progress_bar: True\n    precision: \"16-mixed\"\n    devices: 2\n\nmodel:\n    seg_model: \"Unet\"\n    encoder_name: \"timm-resnest26d\"\n    loss_smooth: 1.0\n    image_size: 384\n    optimizer_params:\n        lr: 0.0005\n        weight_decay: 0.0\n    scheduler:\n        name: \"CosineAnnealingLR\"\n        params:\n            CosineAnnealingLR:\n                T_max: 2\n                eta_min: 1.0e-6\n                last_epoch: -1\n            ReduceLROnPlateau:\n                mode: \"min\"\n                factor: 0.31622776601\n                patience: 4\n                verbose: True","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:36:25.895284Z","iopub.execute_input":"2023-06-16T20:36:25.895707Z","iopub.status.idle":"2023-06-16T20:36:25.906715Z","shell.execute_reply.started":"2023-06-16T20:36:25.895656Z","shell.execute_reply":"2023-06-16T20:36:25.9056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset\n\nimport torch\nimport numpy as np\nimport torchvision.transforms as T\n\nclass ContrailsDataset(torch.utils.data.Dataset):\n    def __init__(self, df, image_size=256, train=True):\n\n        self.df = df\n        self.trn = train\n        self.normalize_image = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n        self.image_size = image_size\n        if image_size != 256:\n            self.resize_image = T.transforms.Resize(image_size)\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        con_path = row.path\n        con = np.load(str(con_path))\n\n        img = con[..., :-1]\n        label = con[..., -1]\n\n        label = torch.tensor(label)\n\n        img = torch.tensor(np.reshape(img, (256, 256, 3))).to(torch.float32).permute(2, 0, 1)\n\n        if self.image_size != 256:\n            img = self.resize_image(img)\n\n        img = self.normalize_image(img)\n\n        return img.float(), label.float()\n\n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:36:25.910441Z","iopub.execute_input":"2023-06-16T20:36:25.910814Z","iopub.status.idle":"2023-06-16T20:36:25.92308Z","shell.execute_reply.started":"2023-06-16T20:36:25.910787Z","shell.execute_reply":"2023-06-16T20:36:25.921848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lightning module\n\nimport torch\nimport pytorch_lightning as pl\nimport segmentation_models_pytorch as smp\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\nfrom torch.optim import AdamW\nimport torch.nn as nn\nfrom torchmetrics.functional import dice\n\nseg_models = {\n    \"Unet\": smp.Unet,\n    \"Unet++\": smp.UnetPlusPlus,\n    \"MAnet\": smp.MAnet,\n    \"Linknet\": smp.Linknet,\n    \"FPN\": smp.FPN,\n    \"PSPNet\": smp.PSPNet,\n    \"PAN\": smp.PAN,\n    \"DeepLabV3\": smp.DeepLabV3,\n    \"DeepLabV3+\": smp.DeepLabV3Plus,\n}\n\n\nclass LightningModule(pl.LightningModule):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        self.model = model = seg_models[config[\"seg_model\"]](\n            encoder_name=config[\"encoder_name\"],\n            encoder_weights=\"imagenet\",\n            in_channels=3,\n            classes=1,\n            activation=None,\n        )\n        self.loss_module = smp.losses.DiceLoss(mode=\"binary\", smooth=config[\"loss_smooth\"])\n        self.val_step_outputs = []\n        self.val_step_labels = []\n\n    def forward(self, batch):\n        imgs = batch\n        preds = self.model(imgs)\n        return preds\n\n    def configure_optimizers(self):\n        optimizer = AdamW(self.parameters(), **self.config[\"optimizer_params\"])\n\n        if self.config[\"scheduler\"][\"name\"] == \"CosineAnnealingLR\":\n            scheduler = CosineAnnealingLR(\n                optimizer,\n                **self.config[\"scheduler\"][\"params\"][\"CosineAnnealingLR\"],\n            )\n            lr_scheduler_dict = {\"scheduler\": scheduler, \"interval\": \"step\"}\n            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_dict}\n        elif self.config[\"scheduler\"][\"name\"] == \"ReduceLROnPlateau\":\n            scheduler = ReduceLROnPlateau(\n                optimizer,\n                **self.config[\"scheduler\"][\"params\"][\"ReduceLROnPlateau\"],\n            )\n            lr_scheduler = {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}\n            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n\n    def training_step(self, batch, batch_idx):\n        imgs, labels = batch\n        preds = self.model(imgs)\n        if self.config[\"image_size\"] != 256:\n            preds = torch.nn.functional.interpolate(preds, size=256, mode='bilinear')\n        loss = self.loss_module(preds, labels)\n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, batch_size=16)\n\n        for param_group in self.trainer.optimizers[0].param_groups:\n            lr = param_group[\"lr\"]\n        self.log(\"lr\", lr, on_step=True, on_epoch=False, prog_bar=True)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        imgs, labels = batch\n        preds = self.model(imgs)\n        if self.config[\"image_size\"] != 256:\n            preds = torch.nn.functional.interpolate(preds, size=256, mode='bilinear')\n        loss = self.loss_module(preds, labels)\n        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.val_step_outputs.append(preds)\n        self.val_step_labels.append(labels)\n\n    def on_validation_epoch_end(self):\n        all_preds = torch.cat(self.val_step_outputs)\n        all_labels = torch.cat(self.val_step_labels)\n        all_preds = torch.sigmoid(all_preds)\n        self.val_step_outputs.clear()\n        self.val_step_labels.clear()\n        val_dice = dice(all_preds, all_labels.long())\n        self.log(\"val_dice\", val_dice, on_step=False, on_epoch=True, prog_bar=True)\n        if self.trainer.global_rank == 0:\n            print(f\"\\nEpoch: {self.current_epoch}\", flush=True)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-16T20:36:25.9251Z","iopub.execute_input":"2023-06-16T20:36:25.925471Z","iopub.status.idle":"2023-06-16T20:36:37.777014Z","shell.execute_reply.started":"2023-06-16T20:36:25.925439Z","shell.execute_reply":"2023-06-16T20:36:37.776111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Actual training\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport torch\nimport yaml\nimport pandas as pd\nimport pytorch_lightning as pl\nfrom pprint import pprint\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\nfrom torch.utils.data import DataLoader\n\nwith open(\"config.yaml\", \"r\") as file_obj:\n    config = yaml.safe_load(file_obj)\n\ncontrails = os.path.join(config[\"data_path\"], \"contrails/\")\ntrain_path = os.path.join(config[\"data_path\"], \"train_df.csv\")\nvalid_path = os.path.join(config[\"data_path\"], \"valid_df.csv\")\n\ntrain_df = pd.read_csv(train_path)\nvalid_df = pd.read_csv(valid_path)\n\ntrain_df[\"path\"] = contrails + train_df[\"record_id\"].astype(str) + \".npy\"\nvalid_df[\"path\"] = contrails + valid_df[\"record_id\"].astype(str) + \".npy\"\n\ndataset_train = ContrailsDataset(train_df, config[\"model\"][\"image_size\"], train=True)\ndataset_validation = ContrailsDataset(valid_df, config[\"model\"][\"image_size\"], train=False)\n\ndata_loader_train = DataLoader(\n    dataset_train,\n    batch_size=config[\"train_bs\"],\n    shuffle=True,\n    num_workers=config[\"workers\"],\n)\ndata_loader_validation = DataLoader(\n    dataset_validation,\n    batch_size=config[\"valid_bs\"],\n    shuffle=False,\n    num_workers=config[\"workers\"],\n)\n\ncheckpoint_callback = ModelCheckpoint(\n    save_weights_only=True,\n    monitor=\"val_dice\",\n    dirpath=config[\"output_dir\"],\n    mode=\"max\",\n    filename=\"model\",\n    save_top_k=1,\n    verbose=1,\n)\n\nprogress_bar_callback = TQDMProgressBar(\n    refresh_rate=config[\"progress_bar_refresh_rate\"]\n)\n\nearly_stop_callback = EarlyStopping(**config[\"early_stop\"])\n\ntrainer = pl.Trainer(\n    callbacks=[checkpoint_callback, early_stop_callback, progress_bar_callback],\n    **config[\"trainer\"],\n)\n\nconfig[\"model\"][\"scheduler\"][\"params\"][\"CosineAnnealingLR\"][\"T_max\"] *= len(data_loader_train)/config[\"trainer\"][\"devices\"]\nmodel = LightningModule(config[\"model\"])\n\ntrainer.fit(model, data_loader_train, data_loader_validation)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:36:37.781651Z","iopub.execute_input":"2023-06-16T20:36:37.784322Z","iopub.status.idle":"2023-06-16T20:48:14.731624Z","shell.execute_reply.started":"2023-06-16T20:36:37.784284Z","shell.execute_reply":"2023-06-16T20:48:14.730204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission part","metadata":{}},{"cell_type":"code","source":"batch_size = 128\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndata = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\ndata_root = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/test/'","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:48:14.735133Z","iopub.execute_input":"2023-06-16T20:48:14.735557Z","iopub.status.idle":"2023-06-16T20:48:14.742885Z","shell.execute_reply.started":"2023-06-16T20:48:14.73552Z","shell.execute_reply":"2023-06-16T20:48:14.74176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = os.listdir(data_root)\ntest_df = pd.DataFrame(filenames, columns=['record_id'])\ntest_df['path'] = data_root + test_df['record_id'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:48:14.744356Z","iopub.execute_input":"2023-06-16T20:48:14.745035Z","iopub.status.idle":"2023-06-16T20:48:14.790212Z","shell.execute_reply.started":"2023-06-16T20:48:14.745004Z","shell.execute_reply":"2023-06-16T20:48:14.789316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ContrailsDataset(torch.utils.data.Dataset):\n    def __init__(self, df, image_size=256, train=True):\n        \n        self.df = df\n        self.trn = train\n        self.df_idx: pd.DataFrame = pd.DataFrame({'idx': os.listdir(f'/kaggle/input/google-research-identify-contrails-reduce-global-warming/test')})\n        self.normalize_image = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n        self.image_size = image_size\n        if image_size != 256:\n            self.resize_image = T.transforms.Resize(image_size)\n    \n    def read_record(self, directory):\n        record_data = {}\n        for x in [\n            \"band_11\", \n            \"band_14\", \n            \"band_15\"\n        ]:\n\n            record_data[x] = np.load(os.path.join(directory, x + \".npy\"))\n\n        return record_data\n\n    def normalize_range(self, data, bounds):\n        \"\"\"Maps data to the range [0, 1].\"\"\"\n        return (data - bounds[0]) / (bounds[1] - bounds[0])\n    \n    def get_false_color(self, record_data):\n        _T11_BOUNDS = (243, 303)\n        _CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n        _TDIFF_BOUNDS = (-4, 2)\n        \n        N_TIMES_BEFORE = 4\n\n        r = self.normalize_range(record_data[\"band_15\"] - record_data[\"band_14\"], _TDIFF_BOUNDS)\n        g = self.normalize_range(record_data[\"band_14\"] - record_data[\"band_11\"], _CLOUD_TOP_TDIFF_BOUNDS)\n        b = self.normalize_range(record_data[\"band_14\"], _T11_BOUNDS)\n        false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n        img = false_color[..., N_TIMES_BEFORE]\n\n        return img\n    \n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        con_path = row.path\n        data = self.read_record(con_path)    \n        \n        img = self.get_false_color(data)\n        \n        img = torch.tensor(np.reshape(img, (256, 256, 3))).to(torch.float32).permute(2, 0, 1)\n        \n        if self.image_size != 256:\n            img = self.resize_image(img)\n        \n        img = self.normalize_image(img)\n        \n        image_id = int(self.df_idx.iloc[index]['idx'])\n            \n        return img.float(), torch.tensor(image_id)\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:48:14.791813Z","iopub.execute_input":"2023-06-16T20:48:14.792405Z","iopub.status.idle":"2023-06-16T20:48:14.808957Z","shell.execute_reply.started":"2023-06-16T20:48:14.792369Z","shell.execute_reply":"2023-06-16T20:48:14.80791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = ContrailsDataset(\n        test_df,\n        config[\"model\"][\"image_size\"],\n        train = False\n    )\n \ntest_dl = DataLoader(test_ds, batch_size=batch_size, num_workers = 1)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:48:14.814203Z","iopub.execute_input":"2023-06-16T20:48:14.81448Z","iopub.status.idle":"2023-06-16T20:48:14.829277Z","shell.execute_reply.started":"2023-06-16T20:48:14.814456Z","shell.execute_reply":"2023-06-16T20:48:14.828308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LightningModule(pl.LightningModule):\n\n    def __init__(self):\n        super().__init__()\n        self.model = smp.Unet(encoder_name=\"timm-resnest26d\",\n                              encoder_weights=None,\n                              in_channels=3,\n                              classes=1,\n                              activation=None,\n                              )\n\n    def forward(self, batch):\n        return self.model(batch)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:48:14.831985Z","iopub.execute_input":"2023-06-16T20:48:14.833306Z","iopub.status.idle":"2023-06-16T20:48:14.83969Z","shell.execute_reply.started":"2023-06-16T20:48:14.833271Z","shell.execute_reply":"2023-06-16T20:48:14.838541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LightningModule().load_from_checkpoint(\"/kaggle/working/models/model.ckpt\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()\nmodel.zero_grad()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-16T20:48:14.841339Z","iopub.execute_input":"2023-06-16T20:48:14.842041Z","iopub.status.idle":"2023-06-16T20:48:22.107356Z","shell.execute_reply.started":"2023-06-16T20:48:14.842001Z","shell.execute_reply":"2023-06-16T20:48:22.106382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode(x, fg_val=1):\n    \"\"\"\n    Args:\n        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n    Returns: run length encoding as list\n    \"\"\"\n\n    dots = np.where(\n        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if b > prev + 1:\n            run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef list_to_string(x):\n    \"\"\"\n    Converts list to a string representation\n    Empty list returns '-'\n    \"\"\"\n    if x: # non-empty list\n        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n    else:\n        s = '-'\n    return s","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:48:22.108796Z","iopub.execute_input":"2023-06-16T20:48:22.109435Z","iopub.status.idle":"2023-06-16T20:48:22.119151Z","shell.execute_reply.started":"2023-06-16T20:48:22.10939Z","shell.execute_reply":"2023-06-16T20:48:22.118035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/google-research-identify-contrails-reduce-global-warming/sample_submission.csv', index_col='record_id')","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:48:22.120756Z","iopub.execute_input":"2023-06-16T20:48:22.121134Z","iopub.status.idle":"2023-06-16T20:48:22.157086Z","shell.execute_reply.started":"2023-06-16T20:48:22.121103Z","shell.execute_reply":"2023-06-16T20:48:22.156241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, data in enumerate(test_dl):\n    images, image_id = data\n    \n    images = images.to(device)\n    with torch.no_grad():\n        predicted_mask = model.forward(images[:, :, :, :])\n    if config[\"model\"][\"image_size\"] != 256:\n        predicted_mask = torch.nn.functional.interpolate(predicted_mask, size=256, mode='bilinear')\n    predicted_mask = torch.sigmoid(predicted_mask).cpu().detach().numpy()\n    \n    predicted_mask_with_threshold = np.zeros((images.shape[0], 256, 256))\n    predicted_mask_with_threshold[predicted_mask[:, 0, :, :] < 0.5] = 0\n    predicted_mask_with_threshold[predicted_mask[:, 0, :, :] > 0.5] = 1\n    \n    for img_num in range(0, images.shape[0]):\n        current_mask = predicted_mask_with_threshold[img_num, :, :]\n        current_image_id = image_id[img_num].item()\n        \n        submission.loc[int(current_image_id), 'encoded_pixels'] = list_to_string(rle_encode(current_mask))","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:48:22.158193Z","iopub.execute_input":"2023-06-16T20:48:22.15852Z","iopub.status.idle":"2023-06-16T20:48:29.408144Z","shell.execute_reply.started":"2023-06-16T20:48:22.15849Z","shell.execute_reply":"2023-06-16T20:48:29.406753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:48:29.410176Z","iopub.execute_input":"2023-06-16T20:48:29.410716Z","iopub.status.idle":"2023-06-16T20:48:29.432594Z","shell.execute_reply.started":"2023-06-16T20:48:29.410672Z","shell.execute_reply":"2023-06-16T20:48:29.430845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-16T20:48:29.434284Z","iopub.execute_input":"2023-06-16T20:48:29.43471Z","iopub.status.idle":"2023-06-16T20:48:29.444928Z","shell.execute_reply.started":"2023-06-16T20:48:29.434672Z","shell.execute_reply":"2023-06-16T20:48:29.443697Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
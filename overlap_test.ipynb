{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "is_kaggle_notebook = \"kaggle_web_client\" in sys.modules\n",
    "if is_kaggle_notebook:\n",
    "    %pip uninstall timm -y\n",
    "    \n",
    "sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\n",
    "sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\n",
    "sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models.pytorch-master')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    debug = False\n",
    "    # ============== comp exp name =============\n",
    "    comp_name = 'contrail'\n",
    "    comp_dir_path = '/kaggle/input/'\n",
    "    comp_folder_name = 'google-research-identify-contrails-reduce-global-warming'\n",
    "\n",
    "    dataset_path = \"/kaggle/working/dataset_test/ash_color/\"\n",
    "\n",
    "    exp_name = \"model01\"\n",
    "\n",
    "    # ============== pred target =============\n",
    "    TTA = is_kaggle_notebook\n",
    "\n",
    "    # ============== training cfg =============\n",
    "    valid_batch_size = 32\n",
    "\n",
    "    # ============== fixed =============\n",
    "    num_workers = 4\n",
    "    seed = 42\n",
    "\n",
    "    # ============== augmentation =============\n",
    "\n",
    "    valid_aug_list = [\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_record(record_id, directory, mode):\n",
    "    record_data = {}\n",
    "    if mode in [\"train\", \"validation\"]:\n",
    "        bands_mask = [\"band_11\", \"band_14\", \"band_15\", \"human_pixel_masks\"]\n",
    "    if mode == \"test\":\n",
    "        bands_mask = [\"band_11\", \"band_14\", \"band_15\"]\n",
    "\n",
    "    for x in bands_mask:\n",
    "        record_data[x] = np.load(os.path.join(directory, record_id, x + \".npy\"))\n",
    "    return record_data\n",
    "\n",
    "\n",
    "def normalize_range(data, bounds):\n",
    "    return (data - bounds[0]) / (bounds[1] - bounds[0])\n",
    "\n",
    "\n",
    "def get_false_color(record_data):\n",
    "    _T11_BOUNDS = (243, 303)\n",
    "    _CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n",
    "    _TDIFF_BOUNDS = (-4, 2)\n",
    "\n",
    "    N_TIMES_BEFORE = 4\n",
    "\n",
    "    r = normalize_range(record_data[\"band_15\"] - record_data[\"band_14\"], _TDIFF_BOUNDS)\n",
    "    g = normalize_range(record_data[\"band_14\"] - record_data[\"band_11\"], _CLOUD_TOP_TDIFF_BOUNDS)\n",
    "    b = normalize_range(record_data[\"band_14\"], _T11_BOUNDS)\n",
    "    false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n",
    "    img = false_color[..., N_TIMES_BEFORE]\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 16.88it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(data_dir, save_dir, mode):\n",
    "    input_dir=f\"{data_dir}/{mode}\"\n",
    "    ids = os.listdir(input_dir)\n",
    "    df = pd.DataFrame(ids, columns=['record_id'])\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    df['path'] = save_dir + df['record_id'].astype(str) + '.npy'\n",
    "    df.to_csv(f\"{save_dir}/{mode}_df.csv\", index=False)\n",
    "\n",
    "    for record_id in tqdm(ids):\n",
    "        data = read_record(str(record_id), input_dir, mode)\n",
    "        images = get_false_color(data)\n",
    "        if mode in [\"train\", \"validation\"]:\n",
    "            array = np.dstack([images, data['human_pixel_masks']])\n",
    "        if mode == \"test\":\n",
    "            array = np.dstack([images])\n",
    "        array = array.astype(np.float16)\n",
    "\n",
    "        npy_path = f\"{save_dir}/{record_id}.npy\"\n",
    "        np.save(str(npy_path), array)\n",
    "\n",
    "        \n",
    "data_dir = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/'\n",
    "dataset_test = \"/kaggle/working/dataset_test/ash_color/\"\n",
    "create_dataset(data_dir, dataset_test, \"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fastnumpyio:\n",
    "    def load(file):\n",
    "        file = open(file, \"rb\")\n",
    "        header = file.read(128)\n",
    "        descr = str(header[19:25], 'utf-8').replace(\"'\", \"\").replace(\" \", \"\")\n",
    "        shape = tuple(int(num) for num in str(header[60:120], 'utf-8').replace(', }', '').replace('(', '').replace(')', '').split(','))\n",
    "        datasize = np.lib.format.descr_to_dtype(descr).itemsize\n",
    "        for dimension in shape:\n",
    "            datasize *= dimension\n",
    "        return np.ndarray(shape, dtype=descr, buffer=file.read(datasize))\n",
    "\n",
    "\n",
    "class ContrailsDataset(Dataset):\n",
    "    def __init__(self, df, transform, mode='train'):\n",
    "        self.df = df\n",
    "        self.transform = A.Compose(transform)\n",
    "        self.mode = mode\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        path = row.path\n",
    "        record_id = row.record_id\n",
    "        npy = fastnumpyio.load(str(path))\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            image = npy[..., :-1]\n",
    "            label = npy[..., -1]\n",
    "            data = self.transform(image=image, mask=label)\n",
    "            image = data['image']\n",
    "            label = data['mask']\n",
    "            label = np.expand_dims(label, 0)\n",
    "            image = torch.tensor(image)\n",
    "            label = torch.tensor(label)\n",
    "            return image.float(), label.float()\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            image = npy\n",
    "            data = self.transform(image=image)\n",
    "            image = data['image']\n",
    "            image = torch.tensor(image)\n",
    "            return image.float(), record_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000834164244036115</td>\n",
       "      <td>/kaggle/working/dataset_test/ash_color/1000834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002653297254493116</td>\n",
       "      <td>/kaggle/working/dataset_test/ash_color/1002653...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             record_id                                               path\n",
       "0  1000834164244036115  /kaggle/working/dataset_test/ash_color/1000834...\n",
       "1  1002653297254493116  /kaggle/working/dataset_test/ash_color/1002653..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(f\"{CFG.dataset_path}/test_df.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len(dataset_test) = 2\n",
      "test_image_shape : torch.Size([3, 256, 256])\n",
      "test_image_dtype : torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_test = ContrailsDataset(test_df, CFG.valid_aug_list, mode='test')\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=CFG.valid_batch_size, num_workers=CFG.num_workers)\n",
    "\n",
    "print(f\"\"\"\n",
    "{len(dataset_test) = }\n",
    "test_image_shape : {dataset_test[0][0].shape}\n",
    "test_image_dtype : {dataset_test[0][0].dtype}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_arch, backbone, in_chans, target_size, weight):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = smp.create_model(\n",
    "            model_arch,\n",
    "            encoder_name=backbone,\n",
    "            encoder_weights=weight,\n",
    "            in_channels=in_chans,\n",
    "            classes=target_size,\n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        output = self.model(image)\n",
    "        return output\n",
    "\n",
    "\n",
    "def build_model(model_arch, backbone, in_chans, target_size, weight=\"imagenet\"):\n",
    "    print('model_arch: ', model_arch)\n",
    "    print('backbone: ', backbone)\n",
    "    model = CustomModel(model_arch, backbone, in_chans, target_size, weight)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_arch:  Unet\n",
      "backbone:  timm-resnest26d\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f'./{CFG.exp_name}/{CFG.exp_name}.pth'):\n",
    "    pth_path = f'./{CFG.exp_name}/{CFG.exp_name}.pth'\n",
    "else:\n",
    "    pth_path = f\"/kaggle/input/{CFG.exp_name}/{CFG.exp_name}.pth\"\n",
    "pth = torch.load(pth_path)\n",
    "\n",
    "\n",
    "model = build_model(pth[\"model_arch\"], pth[\"backbone\"], pth[\"in_chans\"], pth[\"target_size\"], weight=None)\n",
    "model.load_state_dict(pth['model'])\n",
    "thresh = pth['thresh']\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(x):\n",
    "    if x:\n",
    "        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
    "    else:\n",
    "        s = '-'\n",
    "    return s\n",
    "\n",
    "\n",
    "def rle_encode(x, fg_val=1):\n",
    "    dots = np.where(\n",
    "        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if b > prev + 1:\n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.64s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_pixels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>record_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000834164244036115</th>\n",
       "      <td>41481 1 41737 3 41995 3 42254 1 42512 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002653297254493116</th>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              encoded_pixels\n",
       "record_id                                                   \n",
       "1000834164244036115  41481 1 41737 3 41995 3 42254 1 42512 1\n",
       "1002653297254493116                                        -"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-research-identify-contrails-reduce-global-warming/sample_submission.csv', index_col='record_id')\n",
    "\n",
    "for i, (images, record_ids) in tqdm(enumerate(dataloader_test), total=len(dataloader_test)):\n",
    "    images = images.cuda()\n",
    "    with torch.no_grad():\n",
    "        preds = model(images)\n",
    "    preds = torch.sigmoid(preds).cpu().detach().numpy()\n",
    "    preds_thresh = np.where(preds > thresh, 1, 0)\n",
    "\n",
    "    for num in range(images.shape[0]):\n",
    "        pred = preds_thresh[num, 0, :, :]\n",
    "        record_id = int(record_ids[num])\n",
    "        submission.loc[int(record_id), 'encoded_pixels'] = list_to_string(rle_encode(pred))\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from glob import glob\n",
    "import hashlib\n",
    "\n",
    "def calculate_file_hash(file_path, algorithm='md5'):\n",
    "    hash_object = hashlib.new(algorithm)\n",
    "    with open(file_path, 'rb') as file:\n",
    "        for chunk in iter(lambda: file.read(4096*4096), b''):\n",
    "            hash_object.update(chunk)\n",
    "    return hash_object.hexdigest()\n",
    "\n",
    "def has_overlap(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    intersection = set1 & set2\n",
    "    return len(intersection) > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1856/1856 [00:32<00:00, 57.47it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 56.97it/s]\n"
     ]
    }
   ],
   "source": [
    "comp_dir=\"/kaggle/input/google-research-identify-contrails-reduce-global-warming/\"\n",
    "train_dirs = glob(f\"{comp_dir}/train/*\")\n",
    "valid_dirs = glob(f\"{comp_dir}/validation/*\")\n",
    "test_dirs = glob(f\"{comp_dir}/test/*\")\n",
    "train_11_files = [train_dir+\"/band_11.npy\" for train_dir in train_dirs]\n",
    "valid_11_files = [valid_dir+\"/band_11.npy\" for valid_dir in valid_dirs]\n",
    "test_11_files = [train_dir+\"/band_11.npy\" for train_dir in test_dirs]\n",
    "\n",
    "train_file_hashes=[]\n",
    "train_file_names=[]\n",
    "test_file_hashes=[]\n",
    "test_file_names=[]\n",
    "# for train_11_file in tqdm(train_11_files):\n",
    "#     file_hash = calculate_file_hash(train_11_file)\n",
    "#     train_file_names.append(train_11_file)\n",
    "#     train_file_hashes.append(file_hash)\n",
    "    \n",
    "for valid_11_file in tqdm(valid_11_files):\n",
    "    file_hash = calculate_file_hash(valid_11_file)\n",
    "    train_file_names.append(valid_11_file)\n",
    "    train_file_hashes.append(file_hash)\n",
    "\n",
    "for test_11_files in tqdm(test_11_files):\n",
    "    file_hash = calculate_file_hash(test_11_files)\n",
    "    test_file_names.append(test_11_files)\n",
    "    test_file_hashes.append(file_hash)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if has_overlap(train_file_hashes, test_file_hashes):\n",
    "    submission[\"encoded_pixels\"] ='-'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_kaggle_notebook:\n",
    "    shutil.rmtree(CFG.dataset_path)\n",
    "    submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
